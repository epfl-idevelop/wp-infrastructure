# Standard string formatter
format.type = json
format = %{@clientip}h  %{VCL_Log:time_vcl_recv@time_vcl_recv}x  %{VCL_Log:time_vcl_deliver@time_vcl_deliver}x  %{@verb}m  %{Host@http_request.host}i  %{@http_request.path}U  %{@http_request.arguments}q  %{@http_request.protocol}H  %{@code!num}s  %{Referer@referer}i  %{User-agent@agent}i  %{Accept@http_request.accept}i  %{Accept-Encoding@http_request.accept-encoding}i  %{Accept-Language@http_request.accept-language}i  %{Cache-Control@http_request.cache-control}i  %{Connection@http_request.connection}i  %{If-None-Match@http_request.if-none-match}i  %{X-Request-ID@http_request.request-id}i  %{X-Forwarded-For@http_request.x-forwarded-for}i  %{X-Forwarded-Proto@http_request.x-forwarded-proto}i  %{X-EPFL-Trace-Id@http_request.x-epfl-trace-id}i  %{CF-Connecting-IP@http_request.cf-connecting-ip}i  %{Content-Type@http_response.content-type}o  %{Content-Encoding@http_response.content-encoding}o  %{Content-Language@http_response.content-language}o  %{Content-Length@http_response.content-length!num}o  %{Server@http_response.server}o  %{Connection@http_response.connection}o  %{Cache-Control@http_response.cache-control}o  %{Vary@http_response.vary}o  %{Location@http_response.location}o  %{ETag@http_response.etag}o  %{X-Cache-Hits@http_response.x-cache-hits!num}o  %{Age@http_response.age!num}o  %{@http_response.size_bytes!num}b  %{@varnish.total_service_time!num}D  %{Varnish:time_firstbyte@varnish.time_firstbyte!num}x  %{Varnish:handling@varnish.http_request_handling}x

# Where to output varnish log lines:
#  kafka  - (default) send to kafka broker
#  stdout - just print to stdout (behave like varnishncsa)
#  null   - (test) collect all tags specified by format but dont output anything
output = kafka

# The maximum accepted log tag size.
# Larger tags will be truncated to this size.
# Defaults to 2048
#tag.size.max = 2048

# TUNING
# Logline cache hash tuning
# 'logline.hash.size * logline.hash.max' dictates the maximum number of
# cached logline entries in memory.

# Number of hash buckets (keyed by log id).
# Higher number yields more performance at the expense of memory.
# Set this to avg_requests_per_second / 5.
# Defaults to 5000
#logline.hash.size = 5000

# Maximum number of loglines per hash bucket
# Higher number yields less memory consumption at the expense of performance.
# Set this to avg_requests_per_second / logline.hash.size.
# Defaults to 5
#logline.hash.max = 5

# Size of per logline scratch buffer.
# The scratch buffer is used as a temporary storage space while
# collecting tags for the log line.
# If the scratch size is too small the daemon will error-exit
# Defaults to 4MB
#logline.scratch.size = 4194304

# Start for sequence number (%n)
# Either a number, or the string "time" which will set it to the current
# unix time in seconds multiplied by 1,000,000.
# Defaults to 0.
sequence.number = time

#
# varnishkafka log messages configuration
# Debugging, error reporting, etc, not to be confused with varnish logs.
#

# varnishkafka log level (1 = emergencies .. 7 = debug)
log.level = 6

# specify log output (multiples allowed)
log.stderr = true

# Maximum number of error logs produced per log.rate.period seconds
# This setting is applied per error type.
# log.rate.max defaults to 100
# log.rate.period defaults to 60
#log.rate.max = 100
#log.rate.period = 60

# Kafka: log message delivery failures (requires required.acks > 0)
log.kafka.msg.error = true

#
# JSON Statistics
#
# Statistics is collected from varnishkafka itself as well as librdkafka
# Each JSON object has a top level key of either 'varnishkafka' or
# 'kafka' to indicate which type of statistics the object contains.
# Each line is a valid JSON object.
#

# Statistics output interval
# Defaults to 60 seconds, use 0 to disable.
#log.statistics.interval = 60

# Statistics output file
# Defaults to /tmp/varnishkafka.stats.json
log.statistics.file = /dev/stdout

# daemonize varnishkafka (boolean)
daemonize = false

# Varnish-related configuration options:

# -q VSLQ query (https://www.varnish-cache.org/docs/4.1/reference/vsl-query.html)
# varnish.arg.q = not ReqHeader:Content-type

# -n: varnishd instance to get logs from.
# varnish.arg.n = frontend

# -N: VSM filename to read logs from.
# varnish.arg.N = /this/is/a/path

# -T: Max seconds that the VSL API waits between a Begin tag and a End one.
# Varnish workers write log tags to a buffer that gets flushed
# to the shmlog once full. It might happen that a Begin
# tag gets flushed to shmlog as part of a batch without
# its correspondent End tag (for example, due to long requests).
# The VSL default is 120.
# varnish.arg.T = 120

# -L: Upper limit of incomplete VSL transactions kept before
# the oldest one is force completed.
# The VSL default is 1000.
# varnish.arg.L = 1000

#######################################################################
#                                                                     #
# Kafka configuration                                                 #
#                                                                     #
# Kafka configuration properties are prefixed with "kafka."           #
# and topic properties are prefixed with "kafka.topic.".              #
#                                                                     #
# For the full range of Kafka handle and topic configuration          #
# properties, see:                                                    #
#  http://github.com/edenhill/librdkafka/blob/master/CONFIGURATION.md #
#                                                                     #
# And the Apache Kafka configuration reference:                       #
#  http://kafka.apache.org/08/configuration.html                      #
#                                                                     #
#######################################################################

# Initial list of kafka brokers
kafka.metadata.broker.list = exopgesrv106.epfl.ch:9092,exopgesrv107.epfl.ch:9092,exopgesrv108.epfl.ch:9092

# Maximum number of messages allowed on the local producer queue
# Defaults to 1000000
kafka.queue.buffering.max.messages = {{ 100000 if openshift_namespace == 'wwp' else 1000000 }}

# Maximum number of retries per messageset.
kafka.message.send.max.retries = 3

#
# Topic configuration
#

# Topic to produce messages to
kafka.topic = wwp-{{ "prod" if openshift_namespace == 'wwp' else "test" }}-varnish-access

# Partition (-1: random, else one of the available partitions)
kafka.partition = -1

# Required number of acks
kafka.topic.request.required.acks = 1

# Local message timeout (milliseconds)
kafka.topic.message.timeout.ms = 60000

# SO_SNDBUFF Socket send buffer size. System default is used if 0.
# Default is 0.
#kafka.socket.send.buffer.bytes = 0