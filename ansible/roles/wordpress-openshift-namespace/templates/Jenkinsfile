// Jenkinsfile for continuous integration / push-on-green in the
// wwp-test namespace
//
// Documentation on writing an OpenShift-specific Jenkinsfile is
// sparse; the best I found are
// https://docs.openshift.com/container-platform/3.11/dev_guide/dev_tutorials/openshift_pipeline.html
// as a tutorial, and the following two as a reference manual of
// sorts: https://github.com/openshift/jenkins-client-plugin and
// https://github.com/openshift/jenkins-client-plugin/blob/master/examples/jenkins-image-sample.groovy
// The Jenkins UI also provides some clues; try
// https://YOURJENKINSADDRESS/job/wwp-test/job/wwp-test-httpd-jenkins-dev/pipeline-syntax/globals


// We use the new-fangled "Declarative Pipeline" Jenkinsfile syntax
pipeline {
  options {
    timeout(time: 20, unit: 'MINUTES')
  }

  // Here we say that this is to be a nightly build
  triggers {
    // See https://jenkins.io/doc/book/pipeline/syntax/#cron-syntax
    // Note: the time zone is GMT (add 1 or 2 hours to get European
    // time, depending on season)
    cron('H H(2-3) * * *')
  }

  // Here we express where we want the pipeline to execute.
  agent {
    // We want the pipeline to run on a dynamically-run Jenkins slave
    // pod. The `kubernetes { }` stanza that follows is a so-called
    // "Kubernetes plug-in pod template" like Example 2 of
    // https://docs.openshift.com/container-platform/3.11/using_images/other_images/jenkins.html#using-the-jenkins-kubernetes-plug-in
    // except we use the declarative pipeline syntax
    // (https://github.com/jenkinsci/kubernetes-plugin/#declarative-pipeline)
    kubernetes {
      // Label must be unique across the OpenShift namespace; slave pods
      // will be named after it
      label 'jenkins-slave-wwp'
      // The pod template we inheritFrom is auto-generated by the
      // OpenShift sync plug-in from Kubernetes objects (see "Jenkins
      // infrastructure ImageStreams and builds" in
      // ../tasks/continuous-integration.yml)
      inheritFrom "{{ ci_jenkins_slave_image_name }}"
      cloud 'openshift'
      // Using the "yaml" field, we can weave whichever "sidekick"
      // containers we like into the pod template. The main "jnlp"
      // container (not pictured in the YAML) comes from the parent
      // (inheritFrom) template.
      yaml """
apiVersion: v1
kind: Pod
metadata:
  labels:
    some-label: some-label-value
spec:
  containers:
  - name: {{ ci_jenkins_test_sidekick_image_name }}
    image: {{ ci_jenkins_test_sidekick_image_name |
              docker_registry_path_qualified(namespace=openshift_namespace) }}
    command:
    - sleep
    - infinity

{#   # Besides the normal Kubernetes semantics, workingDir is also
     # where the Kubernetes Jenkins plug-in mounts the
     # "workspace-volume" volume, which must be at the same path on all
     # Jenkins masters and slaves (so that paths served over JNLP make
     # sense). While the OpenShift sync plug-in takes care of that for
     # the "jnlp" container, we have to explicitly set it on sidekicks
     # or the `sh` command won't work inside a `container () { }`:
     #}
    workingDir: /tmp
"""
      // 
    }  // kubernetes
  }  // agent

  // Here we describe what the pipeline consists of.
  stages {
    stage('Compilation') {
      steps {
        // Imperative things (including any and all calls to
        // openshift.withCluster and friends) can only happen in a
        // "script".
        script {
          openshift.withCluster() {
            openshift.withProject('{{ openshift_namespace }}') {
              parallel (
                build_varnish: {
                  watchBuild(buildImage('bc/varnish'))
                },
                build_others: {
                  def wpBaseBuild = buildImage('bc/wp-base')
                  watchBuild(wpBaseBuild)
                  watchBuild(awaitTriggeredBuildsStarted(wpBaseBuild, 2))
                }
              )  // parallel
            }  // openshift.withProject
          }  // openshift.withCluster
        }  // script
      }  // steps
    }  // stage('Compilation')

    stage('Tests') {
      steps {
        container('{{ ci_jenkins_test_sidekick_image_name }}') {
          sh "/opt/app/bin/docker-entrypoint --test-target https://migration-wp.epfl.ch/www.epfl.ch/"
        }
      }
    }  // stage('Tests')

  }  // stages

  // Here we set up some post-pipeline hooks to present the results.
  post {
    always {
      cucumber fileIncludePattern: '**/cucumber-report.json', sortingMethod: 'ALPHABETICAL'
    }  // always
  }  // post
}  // pipeline

def buildImage (bcSpec) {
  banner "Building ${bcSpec} in namespace ${openshift.project()}"
  def bc = openshift.selector(bcSpec)
  bc.describe()
  def buildSelector = bc.startBuild()
  buildSelector.describe()
  return buildSelector
}

void watchBuild(buildSelector) {
  def buildUrls = []
  buildSelector.withEach {
    buildUrls.push "https://pub-os-exopge.epfl.ch/console/project/${openshift.project()}/browse/builds/${it.object().metadata.annotations['openshift.io/build-config.name']}/${it.object().metadata.name}?tab=logs"
  }
  if (buildUrls.size() > 0) {
    def hint = (
      ["Vous pouvez suivre la compilation plus confortablement depuis OpenShift :"]
      + buildUrls
    ).join("\n")
    banner hint
  }

  buildSelector.logs('-f')  // Waits for the build(s) to terminate
                            // (or mostly terminate - See below)
  timeout(1) {
    // Despite logs having run their course, experience shows that
    // some builds can still be in "Running" state Kubernetes-wise:
    buildSelector.withEach {
      it.untilEach {
        return it.object().status.phase != "Running"
      }
    }
  }

  def failed = 0
  buildSelector.withEach {
    def status = it.object().status.phase
    if (status != 'Complete') {
      echo "Bad status for ${it.name()}: expected <Complete>, got <${status}>"
      failed++
    }
  }
  if (failed > 0) {
    banner "${failed} failed builds"
    sh "exit 1"  // https://stackoverflow.com/a/51642273/435004
  }
}

void banner (msg) {
  def length = msg.length() + 2
  if (length < 40) {
    length = 40
  }
  if (length > 80) {
    length = 80
  }
  def equals = "=" * length
  msg = [equals, msg, equals].join("\n")
  echo msg
}

void awaitTriggeredBuildsStarted(buildSelector, expectedSize) {
  Set imageIDs = []
  buildSelector.withEach {
    def status = it.object().status
    if (status && status.output && status.output.to
        && status.output.to.imageDigest) {
      imageIDs.add(status.output.to.imageDigest)
    }
  }

  def triggeredBuilds = []

  timeout(2) {
    for (build in openshift.selector("build").objects()) {
      if (build.spec && build.spec.triggeredBy) {
        for (triggered in build.spec.triggeredBy) {
          if (triggered.imageChangeBuild &&
              triggered.imageChangeBuild.imageID &&
              imageIDs.contains(
              triggered.imageChangeBuild.imageID.replaceFirst('.*@', '')))
          {
            triggeredBuilds.add("build/${build.metadata.name}")
          }
        }  // for
      }  // if
    }  // for

    def size = triggeredBuilds.size()
    echo "Found ${size} build(s) triggered by ${buildSelector}: ${triggeredBuilds}"
    return size == expectedSize  // timeout() exit condition
  }  // timeout

  return openshift.selector(triggeredBuilds)
}  // void awaitTriggeredBuildsStarted()
